DATA_PATH=data/xsum-large
MODEL=checkpoint_bestxsum_abex1_UF4_GPUS3_a1_C125.pt
NUM_PARALLEL=3
TEST_FILE=test.source
HYPO_NAME=test.hypo_checkpoint_bestxsum_abex1_UF4_GPUS3_a1_C125.pt
GPU=7

python inference/bart_vae_inference_parallel.py --model $MODEL \
 --data-path $DATA_PATH\
 --parallel $NUM_PARALLEL\
 --test-file $TEST_FILE\
 --hypo $HYPO_NAME\
 --gpu $GPU;


cat ${DATA_PATH}/test.target | java edu.stanford.nlp.process.PTBTokenizer -ioFileList -preserveLines > ${DATA_PATH}/test.target.tokenzied
cat ${DATA_PATH}/${HYPO_NAME} | java edu.stanford.nlp.process.PTBTokenizer -ioFileList -preserveLines > ${DATA_PATH}/${HYPO_NAME}.target
files2rouge ${DATA_PATH}/${HYPO_NAME}.target ${DATA_PATH}/test.target.tokenzied
